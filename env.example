# OLO Temporal Worker – example environment variables
# Copy to .env or export in your shell.

# Comma-separated Temporal task queue names
OLO_QUEUE=olo-chat-queue-oolama,olo-rag-queue-openai

# If true, also poll <queue>-debug for each queue (e.g. olo-chat-queue-oolama-debug, olo-rag-queue-openai-debug)
OLO_IS_DEBUG_ENABLED=true

# Cache (e.g. Redis)
OLO_CACHE_HOST=localhost
OLO_CACHE_PORT=6379

# Database (and run ledger when OLO_RUN_LEDGER=true)
OLO_DB_HOST=localhost
OLO_DB_PORT=5432
# OLO_DB_NAME default: temporal. OLO_DB_USER default: temporal. OLO_DB_PASSWORD default: (empty)

# Run ledger: when true, persist run/node records to DB (tables olo_run, olo_run_node). Default true during development.
# Set to false in production to avoid overhead. Fail-safe: ledger errors do not fail the workflow.
# OLO_RUN_LEDGER=true

# Session key prefix (e.g. Redis). Default: <tenant>:olo:kernel:sessions: (tenant id substituted at runtime).
# Workflow input is stored at getSessionDataPrefix(tenantId) + <transactionId> + :USERINPUT → <tenantId>:olo:kernel:sessions:<transactionId>:USERINPUT
# OLO_SESSION_DATA=<tenant>:olo:kernel:sessions:

# Pipeline config Redis key prefix. Default: <tenant>:olo:kernel:config (tenant id substituted at runtime).
# OLO_CONFIG_KEY_PREFIX=<tenant>:olo:kernel:config

# Comma-separated tenant ids to load pipeline config for at bootstrap when Redis key olo:tenants is not set. Default: default.
# All Redis keys and DB data are scoped by tenant (session/config/quota use tenant-first keys: <tenantId>:olo:...).
# OLO_TENANT_IDS=default,tenant2

# Default tenant id when workflow context.tenantId is missing or blank. Used for config lookup and key scoping.
# If not set, "default" is used. For now set to your primary tenant (e.g. UUID).
OLO_DEFAULT_TENANT_ID=2a2a91fb-f5b4-4cf0-b917-524d242b2e3d

# Optional: store tenant list in Redis at key olo:tenants (JSON array of {"id":"<tenantId>","name":"<display name>"}).
# If present and valid, bootstrap uses this list instead of OLO_TENANT_IDS. Example value:
# [{"id":"2a2a91fb-f5b4-4cf0-b917-524d242b2e3d","name":""},{"id":"another-tenant-id","name":"Other"}]

# Ollama model-executor plugin (used when no tenant-specific config in olo:tenants)
# OLLAMA_BASE_URL defaults to http://localhost:11434
# OLLAMA_MODEL defaults to llama3.2 (open-source Llama 3.2)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.2

# Optional: Ollama embedding plugin (register as OLLAMA_EMBEDDING)
# OLLAMA_EMBEDDING_MODEL=e.g. nomic-embed-text

# Optional: LiteLLM (OpenAI-compatible API over Ollama). Register as LITELLM_EXECUTOR.
# LITELLM_BASE_URL=http://localhost:4000
# LITELLM_MODEL=ollama/llama3.2

# Optional: Qdrant vector store. Register as QDRANT_VECTOR_STORE.
# QDRANT_BASE_URL=http://localhost:6333

# Community plugins: directory scanned for *.jar only (default /opt/olo/plugins). Loaded with restricted classloader (plugin API + slf4j only).
# OLO_PLUGINS_DIR=/opt/olo/plugins

# Optional: Image generation plugins (ship as community JARs in OLO_PLUGINS_DIR or add as internal in PluginManager)
# STABLE_DIFFUSION_BASE_URL=http://localhost:7860
# COMFYUI_BASE_URL=http://localhost:8188
# COMFYUI_CHECKPOINT=v1-5-pruned-emaonly.safetensors
# INVOKEAI_BASE_URL=http://localhost:9090

# Per-tenant quota (soft/hard limits) is configured in olo:tenants config, e.g.:
# "config": { "quota": { "softLimit": 100, "hardLimit": 120 } }
# QuotaFeature (PRE phase) reads current usage from Redis and throws QuotaExceededException if exceeded. Add "quota" to pipeline scope.features to enable.

# Temporal target and namespace come from pipeline configuration (executionDefaults.temporal in config JSON), not from env.
